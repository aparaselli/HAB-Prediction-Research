{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from itertools import permutations\n",
    "from itertools import combinations\n",
    "from pyEDM import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<style>.container { width:90% !important; }</style>'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \n",
    "    message=\"A worker stopped while some jobs were given to the executor.\",\n",
    "    module=\"joblib.externals.loky.process_executor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block(data, num_lags=1, tau=1):\n",
    "    ''' Get a dataframe with all the possible valid lags of the variables. '''\n",
    "    \n",
    "    backward_lags = pd.concat([data[var].shift(lag*tau).rename(f'{var}(t-{lag*tau})') for lag in range(num_lags+1) for var in data.columns], axis=1)\n",
    "    forward_lags  = pd.concat([data[var].shift(-1*lag*tau).rename(f'{var}(t+{lag*tau})') for lag in range(1,num_lags+1) for var in data.columns], axis=1)\n",
    "    block = pd.concat([backward_lags, forward_lags], axis=1)\n",
    "\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xmap_results_smap(block, target, embeddings, Tp, theta, lib, pred):\n",
    "    '''Function to do exhaustive search of embeddings.'''\n",
    "    \n",
    "    def compute_rho(block, target, embedding, Tp, theta, lib, pred):\n",
    "        xmap = SMap(dataFrame=block, target=target, columns=embedding, Tp=Tp, theta=theta, embedded=True, lib=lib, pred=pred, noTime=True)\n",
    "        rho = xmap['predictions'][['Observations', 'Predictions']].corr().iloc[0,1]\n",
    "        return embedding, xmap['predictions'], rho\n",
    "\n",
    "    xmap_results = pd.DataFrame(columns=['embedding', 'rho'])\n",
    "    xmap_results = Parallel(n_jobs=-1)(delayed(compute_rho)(block, target, embedding, Tp, theta, lib, pred) for embedding in embeddings)\n",
    "    xmap_results = pd.DataFrame(xmap_results, columns=['embedding', 'result', 'rho'])\n",
    "    xmap_results = xmap_results.sort_values(by='rho', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return xmap_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiview Cross-Mapping Function\n",
    "\n",
    "def MVCM(block, target, xmap_results, Tp, gap_radius, theta, lib, pred, E, k, self_weight):\n",
    "    \n",
    "    # Get lib and pred indices, adjusted to match pyEDM\n",
    "    lib_start, lib_end = map(int, lib.split())\n",
    "    pred_start, pred_end = map(int, pred.split())\n",
    "    lib_start -= 1; lib_end -= 1\n",
    "    pred_start -= 1; pred_end -= 1\n",
    "    \n",
    "    if Tp > 0:\n",
    "        pred_end += Tp\n",
    "    elif Tp < 0:\n",
    "        pred_start -= -1 * Tp\n",
    "    \n",
    "    # If k > number of system views, return NaNs as the filtered timeseries\n",
    "    if k > len(xmap_results):\n",
    "        filtered_timeseries = pd.DataFrame([np.nan] * len(xmap_results.loc[0,'result']['Predictions']))\n",
    "        return filtered_timeseries\n",
    "    \n",
    "    filter_input = pd.DataFrame()\n",
    "    filter_input = pd.concat([xmap_results.loc[i,'result']['Predictions'] for i in range(0,k)], axis=1)\n",
    "    filter_input.index = block.loc[pred_start:pred_end,:].index\n",
    "    \n",
    "    self = block.loc[pred_start:pred_end,f'{target}(t-0)']\n",
    "    self.index = range(pred_start,pred_end+1)\n",
    "    filter_input['self'] = self\n",
    "    filter_input['vals_to_avg'] = filter_input.apply(lambda row: row.tolist(), axis=1)\n",
    "    \n",
    "    # Get weights based on cross-map skill of embeddings\n",
    "    weights = xmap_results.loc[:k-1,'rho'].tolist()\n",
    "    weights = [x if x >= 0 else 0 for x in weights]                  # Make negative weights 0\n",
    "    \n",
    "    if np.sum(weights) > 0:\n",
    "        weights = [(1 - self_weight/100)*(weight/np.sum(weights)) for weight in weights]\n",
    "    else:\n",
    "        weights = [(1 - self_weight/100)*(1/len(weights)) for weight in weights]\n",
    "    \n",
    "    weights = weights + [self_weight/100]\n",
    "    filter_input['weights'] = [weights] * len(filter_input)\n",
    "    \n",
    "    # Get filtered values\n",
    "    vals_to_avg = np.array(filter_input['vals_to_avg'].tolist())\n",
    "    weights = np.array(filter_input['weights'].tolist())\n",
    "\n",
    "    filter_input['filtered_points'] = np.nansum(vals_to_avg * weights, axis=1)\n",
    "    \n",
    "    filtered_timeseries = filter_input[['filtered_points']].copy()\n",
    "    \n",
    "    # Make sure filtered values are positive\n",
    "    filtered_timeseries[filtered_timeseries<0] = 0\n",
    "    \n",
    "    return filtered_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_parameters_MVCM(block, target, all_xmap_results, Tp, gap_radius, lib, pred, E_list, k_list, theta_list):\n",
    "    \n",
    "    # Get lib and pred indices, adjusted to match pyEDM\n",
    "    lib_start, lib_end = map(int, lib.split())\n",
    "    pred_start, pred_end = map(int, pred.split())\n",
    "    lib_start -= 1; lib_end -= 1\n",
    "    pred_start -= 1; pred_end -= 1\n",
    "    \n",
    "    # Optimize parameters using a self_weight of 0 until a self_weight is chosen at the end\n",
    "    self_weight = 0\n",
    "    \n",
    "    # Choose the E, k, and theta that give the best multiview cross-map prediction of the observed data with a self_weight of 0\n",
    "\n",
    "    xmap_results_dict = {}\n",
    "    \n",
    "    # Get multiview cross-map predictions for E, k, and theta combinations\n",
    "    mvcm_results = pd.DataFrame(columns=['E', 'k', 'theta', 'rho', 'xmap_results', 'noisy_and_filtered'])\n",
    "    \n",
    "    total_iterations = len(list(product(E_list, theta_list, k_list)))\n",
    "    #with tqdm(total=total_iterations) as pbar:\n",
    "    for E, theta in product(E_list, theta_list):\n",
    "\n",
    "        # Get random embeddings and their cross-map skill\n",
    "        xmap_results = {k: v for k, v in all_xmap_results.items() if (k.split('_')[0] == target) & \n",
    "                                                            (k.split('_')[1] == lib) &\n",
    "                                                            (k.split('_')[2] == str(E)) &\n",
    "                                                            (k.split('_')[3] == str(theta))}\n",
    "        key = list(xmap_results.keys())[0]\n",
    "        xmap_results = xmap_results[key]\n",
    "        xmap_results_dict['{0}_{1}'.format(E, theta)] = xmap_results\n",
    "\n",
    "        # Get multiview cross-map predictions for ks in k_list \n",
    "        for k in k_list:\n",
    "\n",
    "            filtered = MVCM(block, target, xmap_results_dict[f'{str(E)}_{str(theta)}'], Tp, gap_radius, theta, lib, pred, E, k, self_weight)\n",
    "\n",
    "            # Align indices of noisy target with indices of filtered_timeseries\n",
    "            noisy_target = block.loc[pred_start:pred_end,f'{target}(t-0)']\n",
    "            noisy_and_filtered = pd.concat([noisy_target, filtered], axis=1)\n",
    "            noisy_and_filtered.columns = [f'noisy_{target}', f'filtered_{target}']\n",
    "            rho = noisy_and_filtered.corr().iloc[0,1]\n",
    "            mvcm_results.loc[len(mvcm_results)] = [E, k, theta, rho, xmap_results, noisy_and_filtered]\n",
    "                #pbar.update(1)\n",
    "\n",
    "    mvcm_results = mvcm_results.sort_values(by='rho', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    E = int(mvcm_results.loc[0,'E'])\n",
    "    k = int(mvcm_results.loc[0,'k'])\n",
    "    theta = int(mvcm_results.loc[0,'theta'])\n",
    "    \n",
    "    return E, k, theta, mvcm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APD_46025(t-0)</th>\n",
       "      <th>ATMP_46025(t-0)</th>\n",
       "      <th>DEWP_46025(t-0)</th>\n",
       "      <th>DPD_46025(t-0)</th>\n",
       "      <th>GST_46025(t-0)</th>\n",
       "      <th>MWD_46025(t-0)</th>\n",
       "      <th>PRES_46025(t-0)</th>\n",
       "      <th>TIDE_46025(t-0)</th>\n",
       "      <th>VIS_46025(t-0)</th>\n",
       "      <th>WDIR_46025(t-0)</th>\n",
       "      <th>...</th>\n",
       "      <th>GST_46025(t+50)</th>\n",
       "      <th>MWD_46025(t+50)</th>\n",
       "      <th>PRES_46025(t+50)</th>\n",
       "      <th>TIDE_46025(t+50)</th>\n",
       "      <th>VIS_46025(t+50)</th>\n",
       "      <th>WDIR_46025(t+50)</th>\n",
       "      <th>WSPD_46025(t+50)</th>\n",
       "      <th>WSPD_lj(t+50)</th>\n",
       "      <th>WTMP_46025(t+50)</th>\n",
       "      <th>WVHT_46025(t+50)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.497083</td>\n",
       "      <td>18.204167</td>\n",
       "      <td>14.841667</td>\n",
       "      <td>14.572917</td>\n",
       "      <td>4.354167</td>\n",
       "      <td>192.500000</td>\n",
       "      <td>1009.750000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>282.916667</td>\n",
       "      <td>...</td>\n",
       "      <td>3.354167</td>\n",
       "      <td>212.333333</td>\n",
       "      <td>1021.220833</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>2.712500</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>0.707500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.457500</td>\n",
       "      <td>17.858333</td>\n",
       "      <td>15.537500</td>\n",
       "      <td>13.681250</td>\n",
       "      <td>3.316667</td>\n",
       "      <td>196.416667</td>\n",
       "      <td>1011.145833</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>173.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.862500</td>\n",
       "      <td>216.083333</td>\n",
       "      <td>1020.445833</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>218.125000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.908696</td>\n",
       "      <td>17.595833</td>\n",
       "      <td>0.907917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.745833</td>\n",
       "      <td>18.829167</td>\n",
       "      <td>15.804167</td>\n",
       "      <td>13.890417</td>\n",
       "      <td>3.291667</td>\n",
       "      <td>196.125000</td>\n",
       "      <td>1011.770833</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>283.458333</td>\n",
       "      <td>...</td>\n",
       "      <td>6.129167</td>\n",
       "      <td>246.875000</td>\n",
       "      <td>1017.941667</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>260.833333</td>\n",
       "      <td>5.037500</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>18.050000</td>\n",
       "      <td>1.493333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.666667</td>\n",
       "      <td>17.587500</td>\n",
       "      <td>15.283333</td>\n",
       "      <td>12.932083</td>\n",
       "      <td>4.037500</td>\n",
       "      <td>194.500000</td>\n",
       "      <td>1013.425000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>255.541667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>248.916667</td>\n",
       "      <td>1016.116667</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>222.291667</td>\n",
       "      <td>4.587500</td>\n",
       "      <td>2.570833</td>\n",
       "      <td>18.058333</td>\n",
       "      <td>1.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.857917</td>\n",
       "      <td>18.595833</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>8.708750</td>\n",
       "      <td>6.204167</td>\n",
       "      <td>247.416667</td>\n",
       "      <td>1012.225000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>300.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.387500</td>\n",
       "      <td>254.375000</td>\n",
       "      <td>1014.483333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>279.708333</td>\n",
       "      <td>7.920833</td>\n",
       "      <td>3.545833</td>\n",
       "      <td>18.479167</td>\n",
       "      <td>1.507083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>6.469167</td>\n",
       "      <td>18.154167</td>\n",
       "      <td>10.450000</td>\n",
       "      <td>10.906250</td>\n",
       "      <td>2.941667</td>\n",
       "      <td>261.916667</td>\n",
       "      <td>1017.208333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>175.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>6.915833</td>\n",
       "      <td>17.866667</td>\n",
       "      <td>52.050000</td>\n",
       "      <td>14.812083</td>\n",
       "      <td>3.683333</td>\n",
       "      <td>246.541667</td>\n",
       "      <td>1016.112500</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>223.291667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>6.949167</td>\n",
       "      <td>17.529167</td>\n",
       "      <td>12.337500</td>\n",
       "      <td>15.577917</td>\n",
       "      <td>3.629167</td>\n",
       "      <td>240.708333</td>\n",
       "      <td>1015.258333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>253.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>9.140833</td>\n",
       "      <td>16.525000</td>\n",
       "      <td>13.254167</td>\n",
       "      <td>16.134583</td>\n",
       "      <td>4.437500</td>\n",
       "      <td>268.416667</td>\n",
       "      <td>1014.595833</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>235.708333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>14.314583</td>\n",
       "      <td>14.495833</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>18.055000</td>\n",
       "      <td>14.033333</td>\n",
       "      <td>300.625000</td>\n",
       "      <td>1009.537500</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>295.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>444 rows × 1414 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     APD_46025(t-0)  ATMP_46025(t-0)  DEWP_46025(t-0)  DPD_46025(t-0)  \\\n",
       "0          6.497083        18.204167        14.841667       14.572917   \n",
       "1          6.457500        17.858333        15.537500       13.681250   \n",
       "2          6.745833        18.829167        15.804167       13.890417   \n",
       "3          5.666667        17.587500        15.283333       12.932083   \n",
       "4          4.857917        18.595833        16.250000        8.708750   \n",
       "..              ...              ...              ...             ...   \n",
       "439        6.469167        18.154167        10.450000       10.906250   \n",
       "440        6.915833        17.866667        52.050000       14.812083   \n",
       "441        6.949167        17.529167        12.337500       15.577917   \n",
       "442        9.140833        16.525000        13.254167       16.134583   \n",
       "443       14.314583        14.495833         8.800000       18.055000   \n",
       "\n",
       "     GST_46025(t-0)  MWD_46025(t-0)  PRES_46025(t-0)  TIDE_46025(t-0)  \\\n",
       "0          4.354167      192.500000      1009.750000             99.0   \n",
       "1          3.316667      196.416667      1011.145833             99.0   \n",
       "2          3.291667      196.125000      1011.770833             99.0   \n",
       "3          4.037500      194.500000      1013.425000             99.0   \n",
       "4          6.204167      247.416667      1012.225000             99.0   \n",
       "..              ...             ...              ...              ...   \n",
       "439        2.941667      261.916667      1017.208333             99.0   \n",
       "440        3.683333      246.541667      1016.112500             99.0   \n",
       "441        3.629167      240.708333      1015.258333             99.0   \n",
       "442        4.437500      268.416667      1014.595833             99.0   \n",
       "443       14.033333      300.625000      1009.537500             99.0   \n",
       "\n",
       "     VIS_46025(t-0)  WDIR_46025(t-0)  ...  GST_46025(t+50)  MWD_46025(t+50)  \\\n",
       "0              99.0       282.916667  ...         3.354167       212.333333   \n",
       "1              99.0       173.375000  ...         2.862500       216.083333   \n",
       "2              99.0       283.458333  ...         6.129167       246.875000   \n",
       "3              99.0       255.541667  ...         5.900000       248.916667   \n",
       "4              99.0       300.750000  ...         9.387500       254.375000   \n",
       "..              ...              ...  ...              ...              ...   \n",
       "439            99.0       175.375000  ...              NaN              NaN   \n",
       "440            99.0       223.291667  ...              NaN              NaN   \n",
       "441            99.0       253.833333  ...              NaN              NaN   \n",
       "442            99.0       235.708333  ...              NaN              NaN   \n",
       "443            99.0       295.083333  ...              NaN              NaN   \n",
       "\n",
       "     PRES_46025(t+50)  TIDE_46025(t+50)  VIS_46025(t+50)  WDIR_46025(t+50)  \\\n",
       "0         1021.220833              99.0             99.0        155.333333   \n",
       "1         1020.445833              99.0             99.0        218.125000   \n",
       "2         1017.941667              99.0             99.0        260.833333   \n",
       "3         1016.116667              99.0             99.0        222.291667   \n",
       "4         1014.483333              99.0             99.0        279.708333   \n",
       "..                ...               ...              ...               ...   \n",
       "439               NaN               NaN              NaN               NaN   \n",
       "440               NaN               NaN              NaN               NaN   \n",
       "441               NaN               NaN              NaN               NaN   \n",
       "442               NaN               NaN              NaN               NaN   \n",
       "443               NaN               NaN              NaN               NaN   \n",
       "\n",
       "     WSPD_46025(t+50)  WSPD_lj(t+50)  WTMP_46025(t+50)  WVHT_46025(t+50)  \n",
       "0            2.712500       1.166667         17.600000          0.707500  \n",
       "1            2.200000       0.908696         17.595833          0.907917  \n",
       "2            5.037500       2.083333         18.050000          1.493333  \n",
       "3            4.587500       2.570833         18.058333          1.585000  \n",
       "4            7.920833       3.545833         18.479167          1.507083  \n",
       "..                ...            ...               ...               ...  \n",
       "439               NaN            NaN               NaN               NaN  \n",
       "440               NaN            NaN               NaN               NaN  \n",
       "441               NaN            NaN               NaN               NaN  \n",
       "442               NaN            NaN               NaN               NaN  \n",
       "443               NaN            NaN               NaN               NaN  \n",
       "\n",
       "[444 rows x 1414 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_data = pd.read_csv('Data/wind_data_w_gaps.csv', index_col=0)#.iloc[304:612] RANGE w/o missing values\n",
    "wind_data = wind_data.drop(columns=['WDIR_lj','WSPD_lj','GST_lj','WVHT_lj','DPD_lj','APD_lj','MWD_lj','PRES_lj','ATMP_lj','WTMP_lj','DEWP_lj','VIS_lj','TIDE_lj'])\n",
    "#wind_data = wind_data.set_index('time')\n",
    "# Put columns in alphabetical order\n",
    "sorted_columns = sorted(wind_data.columns)\n",
    "wind_data = wind_data[sorted_columns]\n",
    "\n",
    "# Make indices integers and save mapping to dates\n",
    "#date_to_int_map = {i: date for i, date in enumerate(HAB_data.index)}\n",
    "#HAB_data.index = range(len(HAB_data))\n",
    "wind_data.index = wind_data.index.astype(int)\n",
    "\n",
    "target = 'WSPD_46025'\n",
    "\n",
    "#HAB_data = HAB_data.drop(['Nitrite_(uM)','Nitrate_(uM)'],axis=1)\n",
    "\n",
    "\n",
    "block = get_block(wind_data.iloc[254:698], num_lags=50, tau=1)\n",
    "block.index = np.arange(block.shape[0])\n",
    "block\n",
    "#HAB_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APD_46025     0\n",
      "ATMP_46025    0\n",
      "DEWP_46025    0\n",
      "DPD_46025     0\n",
      "GST_46025     0\n",
      "MWD_46025     0\n",
      "PRES_46025    0\n",
      "TIDE_46025    0\n",
      "VIS_46025     0\n",
      "WDIR_46025    0\n",
      "WSPD_46025    0\n",
      "WSPD_lj       0\n",
      "WTMP_46025    0\n",
      "WVHT_46025    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(wind_data.iloc[254:698].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block(data, num_lags=1, tau=1):\n",
    "    ''' Get a dataframe with all the possible valid lags of the variables. '''\n",
    "    \n",
    "    backward_lags = pd.concat([data[var].shift(lag*tau).rename(f'{var}(t-{lag*tau})') for lag in range(num_lags+1) for var in data.columns], axis=1)\n",
    "    forward_lags  = pd.concat([data[var].shift(-1*lag*tau).rename(f'{var}(t+{lag*tau})') for lag in range(1,num_lags+1) for var in data.columns], axis=1)\n",
    "    block = pd.concat([backward_lags, forward_lags], axis=1)\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccm(interaction, block, E_list, tau_list, theta_list, Tp, sample=50, sig=0.05):\n",
    "    solver = Ridge(alpha=1.0)#TRYING DIFFERNT SOLVER TO ENSURE CONVERGENCE\n",
    "    print(interaction)\n",
    "    lib = f'1 {len(block)}'\n",
    "    \n",
    "    # Get dataframe with two species of interest\n",
    "    A = interaction[0]; B = interaction[1]\n",
    "    df = block[[f'{A}(t-0)', f'{B}(t-0)']]\n",
    "    \n",
    "    driver = f'{A}(t-0)'\n",
    "    \n",
    "    E_tau_theta_results = pd.DataFrame(columns = ['E', 'tau', 'theta', 'rho'])\n",
    "    for E, tau, theta in list(product(E_list, tau_list, theta_list)):\n",
    "        driven_embedded = [f'{B}(t{i})' if i < 0 else f'{B}(t-{i})' for i in range(E * tau, 1)]\n",
    "        driven_embedded = driven_embedded[::tau][:E]\n",
    "        c = SMap(dataFrame=block, target=driver, columns=driven_embedded, embedded=True, Tp=Tp, theta=theta, lib=lib, pred=lib, noTime=True)\n",
    "        c = c['predictions'][['Observations', 'Predictions']]\n",
    "        rho = c.corr().iloc[0,1]\n",
    "        E_tau_theta_results.loc[len(E_tau_theta_results)] = [E, tau, theta, rho]\n",
    "    E_tau_theta_results = E_tau_theta_results.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Assign E, tau, and theta to be the optimal E, tau, and theta\n",
    "    ccm_value = E_tau_theta_results['rho'].max()\n",
    "    E = int(E_tau_theta_results.loc[np.where(E_tau_theta_results.rho==ccm_value),'E'].item())\n",
    "    tau = int(E_tau_theta_results.loc[np.where(E_tau_theta_results.rho==ccm_value),'tau'].item())\n",
    "    theta = int(E_tau_theta_results.loc[np.where(E_tau_theta_results.rho==ccm_value),'theta'].item())\n",
    "        \n",
    "    # Get convergence p-value\n",
    "    convergence_p_value = get_convergence_p_value(block, sample, A, B, E, Tp, tau, theta)\n",
    "\n",
    "    # Preparing Output\n",
    "    output = {\n",
    "        'target (driver)': A,\n",
    "        'lib (driven)': B,\n",
    "        'E': E,\n",
    "        'tau': tau,\n",
    "        'theta': theta,\n",
    "        'E_tau_theta_results': E_tau_theta_results,\n",
    "        'ccm_value': ccm_value,\n",
    "        'convergence_p_value': convergence_p_value,\n",
    "        'correlation': df.corr().iloc[0,1]\n",
    "    }\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_convergence_p_value(df, sample, A, B, E, Tp, tau, theta):\n",
    "    # Get convergence p-value for CCM (one-tailed t-test on cross-map values using 20% and 50% library sizes)\n",
    "    # H0: μ_20% ≥ μ_50%\n",
    "    # HA: μ_20% < μ_50%\n",
    "    # If p < 0.05, the 20% library size trials have a rho that is significantly smaller than the 50% library trials  \n",
    "    solver = Ridge(alpha=1.0)#TRYING DIFFERNT SOLVER TO ENSURE CONVERGENCE\n",
    "    libsize1 = int(np.ceil(df.shape[0]/5))   # 20% of the full library size\n",
    "    libsize2 = int(np.ceil(df.shape[0]/2))   # 50% of the full library size\n",
    "    \n",
    "    max_iterations = 10 * sample\n",
    "    \n",
    "    # Get list of rhos for libsize1\n",
    "    rhos1 = []; iteration_count = 0\n",
    "    while len(rhos1) < sample and iteration_count < max_iterations:\n",
    "        start = np.random.randint(libsize1, len(df))\n",
    "        library = [start - libsize1, start]\n",
    "        data_subset = df.iloc[library[0]:library[1]]\n",
    "        lib = f'{library[0]+1} {library[1]+1}'\n",
    "        driver = f'{A}(t-0)'\n",
    "        driven_embedded = [f'{B}(t{i})' if i < 0 else f'{B}(t-{i})' for i in range(E * tau, 1)]\n",
    "        driven_embedded = driven_embedded[::tau][:E]\n",
    "        c = SMap(dataFrame=block, target=driver, columns=driven_embedded, embedded=True, Tp=Tp, theta=theta, lib=lib, pred=lib, noTime=True)\n",
    "        c = c['predictions'][['Observations', 'Predictions']]\n",
    "        rho1 = c.corr().iloc[0,1]\n",
    "        if not np.isnan(rho1):\n",
    "            rhos1.append(rho1)\n",
    "        iteration_count += 1\n",
    "        \n",
    "    # Get list of rhos for libsize2\n",
    "    rhos2 = []; iteration_count = 0\n",
    "    while len(rhos2) < sample and iteration_count < max_iterations:\n",
    "        start = np.random.randint(libsize2, len(df))\n",
    "        library = [start - libsize2, start]\n",
    "        data_subset = df.iloc[library[0]:library[1]]\n",
    "        lib = f'{library[0]+1} {library[1]+1}'\n",
    "        driver = f'{A}(t-0)'\n",
    "        driven_embedded = [f'{B}(t{i})' if i < 0 else f'{B}(t-{i})' for i in range(E * tau, 1)]\n",
    "        driven_embedded = driven_embedded[::tau][:E]\n",
    "        c = SMap(dataFrame=block, target=driver, columns=driven_embedded, embedded=True, Tp=Tp, theta=theta, lib=lib, pred=lib, noTime=True)\n",
    "        c = c['predictions'][['Observations', 'Predictions']]\n",
    "        rho2 = c.corr().iloc[0,1]\n",
    "        if not np.isnan(rho2):\n",
    "            rhos2.append(rho2)\n",
    "        iteration_count += 1\n",
    "    \n",
    "    convergence_t_stat, convergence_p_value = ttest_ind(rhos1, rhos2, alternative='less')\n",
    "    \n",
    "    return convergence_p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DEWP_46025', 'WSPD_46025')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'target (driver)': 'DEWP_46025',\n",
       " 'lib (driven)': 'WSPD_46025',\n",
       " 'E': 2,\n",
       " 'tau': -1,\n",
       " 'theta': 0,\n",
       " 'E_tau_theta_results':         E  tau  theta       rho\n",
       " 0     2.0 -1.0    0.0  0.111730\n",
       " 1     2.0 -1.0    0.1  0.111206\n",
       " 2     2.0 -1.0    0.5  0.107390\n",
       " 3     2.0 -1.0    1.0  0.103046\n",
       " 4     2.0 -1.0    2.0  0.095347\n",
       " ..    ...  ...    ...       ...\n",
       " 391  12.0 -3.0    5.0 -0.028955\n",
       " 392  12.0 -3.0    6.0 -0.026260\n",
       " 393  12.0 -3.0    7.0 -0.024765\n",
       " 394  12.0 -3.0    8.0 -0.023893\n",
       " 395  12.0 -3.0    9.0 -0.023265\n",
       " \n",
       " [396 rows x 4 columns],\n",
       " 'ccm_value': 0.11172961233759171,\n",
       " 'convergence_p_value': 0.03120008369838317,\n",
       " 'correlation': -0.11619884994445032}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_list = range(2,13)\n",
    "tau_list = [-1,-2,-3]\n",
    "theta_list = [0,0.1,0.5,1,2,3,4,5,6,7,8,9]\n",
    "Tp = 0\n",
    "exclusion_radius = 0\n",
    "\n",
    "all_ccm_results = pd.DataFrame()\n",
    "interactions = list(permutations(wind_data.columns.tolist(),2))\n",
    "target_interactions = [pair for pair in interactions if target in pair]\n",
    "\n",
    "interaction = target_interactions[0]\n",
    "ccm(target_interactions[2], block, E_list, tau_list, theta_list, Tp)\n",
    "#results = Parallel(n_jobs=2)(\n",
    "#    delayed(ccm)(interaction, block, E_list, tau_list, theta_list, Tp) for interaction in target_interactions[:8]) #CHaNGED TO FIRST 8 FOR SIMPLICITY\n",
    "#results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get CCM results that show convergence (convergence p-value < 0.05)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m ccm_cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m----> 5\u001b[0m significant_results \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m[results_df\u001b[38;5;241m.\u001b[39mconvergence_p_value\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0.05\u001b[39m]\n\u001b[1;32m      6\u001b[0m significant_results \u001b[38;5;241m=\u001b[39m significant_results\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccm_value\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m significant_results \u001b[38;5;241m=\u001b[39m significant_results[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget (driver)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlib (driven)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtau\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccm_value\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Get CCM results that show convergence (convergence p-value < 0.05)\n",
    "\n",
    "ccm_cutoff = 0.5\n",
    "\n",
    "significant_results = results_df[results_df.convergence_p_value<0.05]\n",
    "significant_results = significant_results.sort_values(by='ccm_value', ascending=False)\n",
    "significant_results = significant_results[['target (driver)', 'lib (driven)', 'E', 'tau', 'theta', 'ccm_value']].reset_index(drop=True)\n",
    "\n",
    "display(significant_results[significant_results.ccm_value>ccm_cutoff])\n",
    "\n",
    "# Choose system variables where the CCM value to or from the target is > ccm_cutoff\n",
    "system_variables = significant_results[significant_results.ccm_value > ccm_cutoff]\n",
    "system_variables = system_variables[['target (driver)', 'lib (driven)']].values.flatten().tolist()\n",
    "system_variables = list(set(system_variables))\n",
    "print('system variables: ')\n",
    "display(sorted(system_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Phosphate_(uM)(t-0)', 'Phosphate_(uM)(t-3)', 'Phosphate_(uM)(t+3)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_valid_lags_tau(block, target, Tp, tau, num_lags, exclusion_radius, system_variables):\n",
    "    \n",
    "    # Get lags of system variables\n",
    "    system_variable_lags = []\n",
    "    for var in system_variables:\n",
    "        # Get forwards and backwards lag of the system variables\n",
    "        var_backwards_lags = [f'{var}(t{i})' if i < 0 else f'{var}(t-{i})' for i in range(num_lags * tau, 1)]\n",
    "        var_backwards_lags = var_backwards_lags[::tau][:num_lags]\n",
    "        var_forwards_lags  = [f'{var}(t+{i})' for i in range(-(num_lags-1) * tau + 1)]\n",
    "        var_forwards_lags  = var_forwards_lags[::tau][:num_lags-1]\n",
    "        var_lags = var_backwards_lags + var_forwards_lags\n",
    "        system_variable_lags = system_variable_lags + var_lags\n",
    "    \n",
    "    # Remove (t-0) lag of target variable from valid_lags\n",
    "    valid_lags = [x for x in system_variable_lags if x != f'{target}(t-0)']\n",
    "\n",
    "    # If Tp = 0, remove [-exclusion_radius, exclusion_radius] lags of target variable from valid lags\n",
    "    if Tp == 0:\n",
    "        for r in range(-exclusion_radius, exclusion_radius+1):\n",
    "            if r < 0:\n",
    "                valid_lags = [x for x in valid_lags if x != f'{target}(t{r})']\n",
    "            elif r == 0:\n",
    "                valid_lags = [x for x in valid_lags if x != f'{target}(t-{r})']\n",
    "            elif r > 0:\n",
    "                valid_lags = [x for x in valid_lags if x != f'{target}(t+{r})']\n",
    "                    \n",
    "    return valid_lags\n",
    "\n",
    "#target = 'Planktothrix_rubescens'\n",
    "system_variables = system_variables\n",
    "Tp = 0\n",
    "exclusion_radius = 6\n",
    "num_lags = 2   # Use -3, 0, and +3 lags of each variable\n",
    "tau = -3\n",
    "\n",
    "valid_lags = get_valid_lags_tau(block, target, Tp, tau, num_lags, exclusion_radius, system_variables)\n",
    "valid_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E = 1, # embeddings = 3\n",
      "E = 2, # embeddings = 3\n"
     ]
    }
   ],
   "source": [
    "random_embeddings = {}\n",
    "for E in range(1,3):\n",
    "    # Get random embeddings using valid lags\n",
    "    embeddings = set()\n",
    "    sample = 3#100000\n",
    "    max_trials = 5#10000000\n",
    "    trials = 0\n",
    "    while len(embeddings) < sample and trials < max_trials:\n",
    "        embedding = tuple(random.sample(valid_lags, E))\n",
    "        sorted_embedding = tuple(sorted(embedding))\n",
    "        if sorted_embedding not in embeddings:\n",
    "            embeddings.add(sorted_embedding)\n",
    "    trials += 1\n",
    "    embeddings = [list(embedding) for embedding in embeddings]\n",
    "    random_embeddings['{0}'.format((target, E, Tp, exclusion_radius))] = embeddings\n",
    "    print(f'E = {E}, # embeddings = {len(embeddings)}')\n",
    "    \n",
    "with open('random_embeddings_HAB.pkl', 'wb') as file:\n",
    "     pickle.dump(random_embeddings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"('Avg_Chloro_(mg/m3)', 1, 0, 0)\": [['Phosphate_(uM)(t+3)'],\n",
       "  ['Phosphate_(uM)(t-0)'],\n",
       "  ['Phosphate_(uM)(t-3)']],\n",
       " \"('Avg_Chloro_(mg/m3)', 2, 0, 0)\": [['Phosphate_(uM)(t-0)',\n",
       "   'Phosphate_(uM)(t-3)'],\n",
       "  ['Phosphate_(uM)(t+3)', 'Phosphate_(uM)(t-3)'],\n",
       "  ['Phosphate_(uM)(t+3)', 'Phosphate_(uM)(t-0)']]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load HAB random embeddings\n",
    "with open('random_embeddings_HAB.pkl', 'rb') as file:\n",
    "    HAB_embeddings = pickle.load(file)\n",
    "HAB_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to store xmap results\n",
    "folder = 'xmap results HAB 100000 random embeddings'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/147 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m key \u001b[38;5;241m=\u001b[39m [key \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m HAB_embeddings\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28meval\u001b[39m(key)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m target \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28meval\u001b[39m(key)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m E \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28meval\u001b[39m(key)[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m Tp \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28meval\u001b[39m(key)[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m==\u001b[39m exclusion_radius]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(key)\n\u001b[0;32m---> 22\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m HAB_embeddings[\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     24\u001b[0m xmap_results \u001b[38;5;241m=\u001b[39m get_xmap_results_smap(block, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(t-0)\u001b[39m\u001b[38;5;124m'\u001b[39m, embeddings, Tp, theta, lib, lib)\n\u001b[1;32m     26\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxmap_results_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Tp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_E_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_theta_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtheta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Save HAB cross-mapping results\n",
    "\n",
    "E_list = range(4,25)\n",
    "theta_list = [1,5,9,15,25,35,45]\n",
    "Tp = 0\n",
    "exclusion_radius = 6\n",
    "self_weight = 0  # self_weight = 0 for gap filling\n",
    "lib = '1 832' #CHANGE TO LIBRARY SIZE\n",
    "pred = '1 832'\n",
    "\n",
    "total_iterations = len(E_list) * len(theta_list)\n",
    "\n",
    "gapfill_results = {}\n",
    "parameters = pd.DataFrame(columns=['target', 'noise_level', 'lib', 'pred', 'E', 'theta', 'k', 'rho'])\n",
    "block = get_block(HAB_data, num_lags=50)\n",
    "\n",
    "with tqdm(total=total_iterations) as pbar:\n",
    "    for E, theta in product(E_list, theta_list):\n",
    "\n",
    "        key = [key for key in HAB_embeddings.keys() if eval(key)[0] == target and eval(key)[1] == E and eval(key)[2] == Tp and eval(key)[3] == exclusion_radius]\n",
    "        print(key)\n",
    "        embeddings = HAB_embeddings[key[0]]\n",
    "\n",
    "        xmap_results = get_xmap_results_smap(block, f'{target}(t-0)', embeddings, Tp, theta, lib, lib)\n",
    "\n",
    "        file_path = os.path.join(folder, f'xmap_results_{target}_Tp_{Tp}_E_{E}_theta_{theta}.pkl')\n",
    "\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(xmap_results, f)\n",
    "\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([\"('Avg_Chloro_(mg/m3)', 1, 0, 0)\", \"('Avg_Chloro_(mg/m3)', 2, 0, 0)\"])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAB_embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyedm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
