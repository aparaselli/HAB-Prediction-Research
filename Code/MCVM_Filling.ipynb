{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from itertools import permutations\n",
    "from itertools import combinations\n",
    "from pyEDM import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('<style>.container { width:90% !important; }</style>'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \n",
    "    message=\"A worker stopped while some jobs were given to the executor.\",\n",
    "    module=\"joblib.externals.loky.process_executor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block(data, num_lags=1, tau=1):\n",
    "    ''' Get a dataframe with all the possible valid lags of the variables. '''\n",
    "    \n",
    "    backward_lags = pd.concat([data[var].shift(lag*tau).rename(f'{var}(t-{lag*tau})') for lag in range(num_lags+1) for var in data.columns], axis=1)\n",
    "    forward_lags  = pd.concat([data[var].shift(-1*lag*tau).rename(f'{var}(t+{lag*tau})') for lag in range(1,num_lags+1) for var in data.columns], axis=1)\n",
    "    block = pd.concat([backward_lags, forward_lags], axis=1)\n",
    "\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_lags(all_lags, target, gap_radius, Tp):\n",
    "    \n",
    "    system_variables = []#'R', 'C1', 'C2', 'P1', 'P2'\n",
    "    \n",
    "    valid_lags = all_lags.copy()\n",
    "    \n",
    "    # If Tp = 0, remove [-gap_radius, gap_radius] lags of target variable from valid_lags\n",
    "    if Tp == 0:\n",
    "        for r in range(-gap_radius, gap_radius+1):\n",
    "            if r < 0:\n",
    "                valid_lags = [x for x in valid_lags if x != f'{target}(t{r})']\n",
    "            elif r == 0:\n",
    "                valid_lags = [x for x in valid_lags if x != f'{target}(t-{r})']\n",
    "            elif r > 0:\n",
    "                valid_lags = [x for x in valid_lags if x != f'{target}(t+{r})']\n",
    "            \n",
    "    # If Tp != 0, remove sgn(Tp)*[1,2r+1] lags of all variables from valid lags\n",
    "    elif Tp != 0:\n",
    "        sgn_Tp = int(math.copysign(1, Tp))\n",
    "        lags_to_remove = [sgn_Tp * l for l in list(range(1,2*gap_radius+1 + 1))]\n",
    "        for lag in lags_to_remove:\n",
    "            for var in system_variables:\n",
    "                if lag < 0:\n",
    "                    valid_lags = [x for x in valid_lags if x != f'{var}(t{lag})']\n",
    "                elif lag == 0:\n",
    "                    valid_lags = [x for x in valid_lags if x != f'{var}(t-{lag})']\n",
    "                elif lag > 0:\n",
    "                    valid_lags = [x for x in valid_lags if x != f'{var}(t+{lag})']\n",
    "            \n",
    "    return valid_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xmap_results_smap(block, target, embeddings, Tp, theta, lib, pred):\n",
    "    '''Function to do exhaustive search of embeddings.'''\n",
    "    \n",
    "    def compute_rho(block, target, embedding, Tp, theta, lib, pred):\n",
    "        xmap = SMap(dataFrame=block, target=target, columns=embedding, Tp=Tp, theta=theta, embedded=True, lib=lib, pred=pred, noTime=True)\n",
    "        rho = xmap['predictions'][['Observations', 'Predictions']].corr().iloc[0,1]\n",
    "        return embedding, xmap['predictions'], rho\n",
    "\n",
    "    xmap_results = pd.DataFrame(columns=['embedding', 'rho'])\n",
    "    xmap_results = Parallel(n_jobs=-1)(delayed(compute_rho)(block, target, embedding, Tp, theta, lib, pred) for embedding in embeddings)\n",
    "    xmap_results = pd.DataFrame(xmap_results, columns=['embedding', 'result', 'rho'])\n",
    "    xmap_results = xmap_results.sort_values(by='rho', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return xmap_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiview Cross-Mapping Function\n",
    "\n",
    "def MVCM(block, target, xmap_results, Tp, gap_radius, theta, lib, pred, E, k, self_weight):\n",
    "    \n",
    "    # Get lib and pred indices, adjusted to match pyEDM\n",
    "    lib_start, lib_end = map(int, lib.split())\n",
    "    pred_start, pred_end = map(int, pred.split())\n",
    "    lib_start -= 1; lib_end -= 1\n",
    "    pred_start -= 1; pred_end -= 1\n",
    "    \n",
    "    if Tp > 0:\n",
    "        pred_end += Tp\n",
    "    elif Tp < 0:\n",
    "        pred_start -= -1 * Tp\n",
    "    \n",
    "    # If k > number of system views, return NaNs as the filtered timeseries\n",
    "    if k > len(xmap_results):\n",
    "        filtered_timeseries = pd.DataFrame([np.nan] * len(xmap_results.loc[0,'result']['Predictions']))\n",
    "        return filtered_timeseries\n",
    "    \n",
    "    filter_input = pd.DataFrame()\n",
    "    filter_input = pd.concat([xmap_results.loc[i,'result']['Predictions'] for i in range(0,k)], axis=1)\n",
    "    filter_input.index = block.loc[pred_start:pred_end,:].index\n",
    "    \n",
    "    self = block.loc[pred_start:pred_end,f'{target}(t-0)']\n",
    "    self.index = range(pred_start,pred_end+1)\n",
    "    filter_input['self'] = self\n",
    "    filter_input['vals_to_avg'] = filter_input.apply(lambda row: row.tolist(), axis=1)\n",
    "    \n",
    "    # Get weights based on cross-map skill of embeddings\n",
    "    weights = xmap_results.loc[:k-1,'rho'].tolist()\n",
    "    weights = [x if x >= 0 else 0 for x in weights]                  # Make negative weights 0\n",
    "    \n",
    "    if np.sum(weights) > 0:\n",
    "        weights = [(1 - self_weight/100)*(weight/np.sum(weights)) for weight in weights]\n",
    "    else:\n",
    "        weights = [(1 - self_weight/100)*(1/len(weights)) for weight in weights]\n",
    "    \n",
    "    weights = weights + [self_weight/100]\n",
    "    filter_input['weights'] = [weights] * len(filter_input)\n",
    "    \n",
    "    # Get filtered values\n",
    "    vals_to_avg = np.array(filter_input['vals_to_avg'].tolist())\n",
    "    weights = np.array(filter_input['weights'].tolist())\n",
    "\n",
    "    filter_input['filtered_points'] = np.nansum(vals_to_avg * weights, axis=1)\n",
    "    \n",
    "    filtered_timeseries = filter_input[['filtered_points']].copy()\n",
    "    \n",
    "    # Make sure filtered values are positive\n",
    "    filtered_timeseries[filtered_timeseries<0] = 0\n",
    "    \n",
    "    return filtered_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_parameters_MVCM(block, target, all_xmap_results, Tp, gap_radius, lib, pred, E_list, k_list, theta_list):\n",
    "    \n",
    "    # Get lib and pred indices, adjusted to match pyEDM\n",
    "    lib_start, lib_end = map(int, lib.split())\n",
    "    pred_start, pred_end = map(int, pred.split())\n",
    "    lib_start -= 1; lib_end -= 1\n",
    "    pred_start -= 1; pred_end -= 1\n",
    "    \n",
    "    # Optimize parameters using a self_weight of 0 until a self_weight is chosen at the end\n",
    "    self_weight = 0\n",
    "    \n",
    "    # Choose the E, k, and theta that give the best multiview cross-map prediction of the observed data with a self_weight of 0\n",
    "\n",
    "    xmap_results_dict = {}\n",
    "    \n",
    "    # Get multiview cross-map predictions for E, k, and theta combinations\n",
    "    mvcm_results = pd.DataFrame(columns=['E', 'k', 'theta', 'rho', 'xmap_results', 'noisy_and_filtered'])\n",
    "    \n",
    "    total_iterations = len(list(product(E_list, theta_list, k_list)))\n",
    "    #with tqdm(total=total_iterations) as pbar:\n",
    "    for E, theta in product(E_list, theta_list):\n",
    "\n",
    "        # Get random embeddings and their cross-map skill\n",
    "        xmap_results = {k: v for k, v in all_xmap_results.items() if (k.split('_')[0] == target) & \n",
    "                                                            (k.split('_')[1] == lib) &\n",
    "                                                            (k.split('_')[2] == str(E)) &\n",
    "                                                            (k.split('_')[3] == str(theta))}\n",
    "        key = list(xmap_results.keys())[0]\n",
    "        xmap_results = xmap_results[key]\n",
    "        xmap_results_dict['{0}_{1}'.format(E, theta)] = xmap_results\n",
    "\n",
    "        # Get multiview cross-map predictions for ks in k_list \n",
    "        for k in k_list:\n",
    "\n",
    "            filtered = MVCM(block, target, xmap_results_dict[f'{str(E)}_{str(theta)}'], Tp, gap_radius, theta, lib, pred, E, k, self_weight)\n",
    "\n",
    "            # Align indices of noisy target with indices of filtered_timeseries\n",
    "            noisy_target = block.loc[pred_start:pred_end,f'{target}(t-0)']\n",
    "            noisy_and_filtered = pd.concat([noisy_target, filtered], axis=1)\n",
    "            noisy_and_filtered.columns = [f'noisy_{target}', f'filtered_{target}']\n",
    "            rho = noisy_and_filtered.corr().iloc[0,1]\n",
    "            mvcm_results.loc[len(mvcm_results)] = [E, k, theta, rho, xmap_results, noisy_and_filtered]\n",
    "                #pbar.update(1)\n",
    "\n",
    "    mvcm_results = mvcm_results.sort_values(by='rho', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    E = int(mvcm_results.loc[0,'E'])\n",
    "    k = int(mvcm_results.loc[0,'k'])\n",
    "    theta = int(mvcm_results.loc[0,'theta'])\n",
    "    \n",
    "    return E, k, theta, mvcm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_Chloro_(mg/m3)(t-0)</th>\n",
       "      <th>Nitrate_(uM)(t-0)</th>\n",
       "      <th>Phosphate_(uM)(t-0)</th>\n",
       "      <th>Silicate_(uM)(t-0)</th>\n",
       "      <th>Avg_Chloro_(mg/m3)(t-1)</th>\n",
       "      <th>Nitrate_(uM)(t-1)</th>\n",
       "      <th>Phosphate_(uM)(t-1)</th>\n",
       "      <th>Silicate_(uM)(t-1)</th>\n",
       "      <th>Avg_Chloro_(mg/m3)(t-2)</th>\n",
       "      <th>Nitrate_(uM)(t-2)</th>\n",
       "      <th>...</th>\n",
       "      <th>Phosphate_(uM)(t+48)</th>\n",
       "      <th>Silicate_(uM)(t+48)</th>\n",
       "      <th>Avg_Chloro_(mg/m3)(t+49)</th>\n",
       "      <th>Nitrate_(uM)(t+49)</th>\n",
       "      <th>Phosphate_(uM)(t+49)</th>\n",
       "      <th>Silicate_(uM)(t+49)</th>\n",
       "      <th>Avg_Chloro_(mg/m3)(t+50)</th>\n",
       "      <th>Nitrate_(uM)(t+50)</th>\n",
       "      <th>Phosphate_(uM)(t+50)</th>\n",
       "      <th>Silicate_(uM)(t+50)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time (UTC)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.73</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>2.20</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.29</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.29</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4250</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>1.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Avg_Chloro_(mg/m3)(t-0)  Nitrate_(uM)(t-0)  Phosphate_(uM)(t-0)  \\\n",
       "time (UTC)                                                                    \n",
       "2128                           1.73               0.57                 0.17   \n",
       "2135                           2.20               1.70                 0.29   \n",
       "2142                           0.57               0.00                 0.16   \n",
       "2149                           0.70               0.21                 0.17   \n",
       "2157                           0.74               0.26                 0.16   \n",
       "...                             ...                ...                  ...   \n",
       "4250                           0.90               0.39                 0.33   \n",
       "4256                           0.84               0.00                 0.28   \n",
       "4263                           0.83               0.00                 0.23   \n",
       "4270                           0.72               0.55                 0.25   \n",
       "4277                           1.73               0.00                 0.16   \n",
       "\n",
       "            Silicate_(uM)(t-0)  Avg_Chloro_(mg/m3)(t-1)  Nitrate_(uM)(t-1)  \\\n",
       "time (UTC)                                                                   \n",
       "2128                       2.6                      NaN                NaN   \n",
       "2135                       5.5                     1.73               0.57   \n",
       "2142                       3.0                     2.20               1.70   \n",
       "2149                       5.1                     0.57               0.00   \n",
       "2157                       5.4                     0.70               0.21   \n",
       "...                        ...                      ...                ...   \n",
       "4250                       2.5                     0.99               0.00   \n",
       "4256                       2.4                     0.90               0.39   \n",
       "4263                       2.1                     0.84               0.00   \n",
       "4270                       2.0                     0.83               0.00   \n",
       "4277                       2.3                     0.72               0.55   \n",
       "\n",
       "            Phosphate_(uM)(t-1)  Silicate_(uM)(t-1)  Avg_Chloro_(mg/m3)(t-2)  \\\n",
       "time (UTC)                                                                     \n",
       "2128                        NaN                 NaN                      NaN   \n",
       "2135                       0.17                 2.6                      NaN   \n",
       "2142                       0.29                 5.5                     1.73   \n",
       "2149                       0.16                 3.0                     2.20   \n",
       "2157                       0.17                 5.1                     0.57   \n",
       "...                         ...                 ...                      ...   \n",
       "4250                       0.26                 2.9                     0.80   \n",
       "4256                       0.33                 2.5                     0.99   \n",
       "4263                       0.28                 2.4                     0.90   \n",
       "4270                       0.23                 2.1                     0.84   \n",
       "4277                       0.25                 2.0                     0.83   \n",
       "\n",
       "            Nitrate_(uM)(t-2)  ...  Phosphate_(uM)(t+48)  Silicate_(uM)(t+48)  \\\n",
       "time (UTC)                     ...                                              \n",
       "2128                      NaN  ...                  0.13                  1.2   \n",
       "2135                      NaN  ...                  0.17                  1.8   \n",
       "2142                     0.57  ...                  0.20                  3.9   \n",
       "2149                     1.70  ...                  0.36                  6.5   \n",
       "2157                     0.00  ...                  0.25                  3.2   \n",
       "...                       ...  ...                   ...                  ...   \n",
       "4250                     0.00  ...                   NaN                  NaN   \n",
       "4256                     0.00  ...                   NaN                  NaN   \n",
       "4263                     0.39  ...                   NaN                  NaN   \n",
       "4270                     0.00  ...                   NaN                  NaN   \n",
       "4277                     0.00  ...                   NaN                  NaN   \n",
       "\n",
       "            Avg_Chloro_(mg/m3)(t+49)  Nitrate_(uM)(t+49)  \\\n",
       "time (UTC)                                                 \n",
       "2128                            1.33                0.18   \n",
       "2135                            1.07                0.24   \n",
       "2142                            2.04                2.38   \n",
       "2149                            1.14                0.59   \n",
       "2157                            1.52                0.44   \n",
       "...                              ...                 ...   \n",
       "4250                             NaN                 NaN   \n",
       "4256                             NaN                 NaN   \n",
       "4263                             NaN                 NaN   \n",
       "4270                             NaN                 NaN   \n",
       "4277                             NaN                 NaN   \n",
       "\n",
       "            Phosphate_(uM)(t+49)  Silicate_(uM)(t+49)  \\\n",
       "time (UTC)                                              \n",
       "2128                        0.17                  1.8   \n",
       "2135                        0.20                  3.9   \n",
       "2142                        0.36                  6.5   \n",
       "2149                        0.25                  3.2   \n",
       "2157                        0.19                  2.8   \n",
       "...                          ...                  ...   \n",
       "4250                         NaN                  NaN   \n",
       "4256                         NaN                  NaN   \n",
       "4263                         NaN                  NaN   \n",
       "4270                         NaN                  NaN   \n",
       "4277                         NaN                  NaN   \n",
       "\n",
       "            Avg_Chloro_(mg/m3)(t+50)  Nitrate_(uM)(t+50)  \\\n",
       "time (UTC)                                                 \n",
       "2128                            1.07                0.24   \n",
       "2135                            2.04                2.38   \n",
       "2142                            1.14                0.59   \n",
       "2149                            1.52                0.44   \n",
       "2157                            1.85                0.28   \n",
       "...                              ...                 ...   \n",
       "4250                             NaN                 NaN   \n",
       "4256                             NaN                 NaN   \n",
       "4263                             NaN                 NaN   \n",
       "4270                             NaN                 NaN   \n",
       "4277                             NaN                 NaN   \n",
       "\n",
       "            Phosphate_(uM)(t+50)  Silicate_(uM)(t+50)  \n",
       "time (UTC)                                             \n",
       "2128                        0.20                  3.9  \n",
       "2135                        0.36                  6.5  \n",
       "2142                        0.25                  3.2  \n",
       "2149                        0.19                  2.8  \n",
       "2157                        0.18                  3.4  \n",
       "...                          ...                  ...  \n",
       "4250                         NaN                  NaN  \n",
       "4256                         NaN                  NaN  \n",
       "4263                         NaN                  NaN  \n",
       "4270                         NaN                  NaN  \n",
       "4277                         NaN                  NaN  \n",
       "\n",
       "[308 rows x 404 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAB_data = pd.read_csv('Data/data_w_gaps.csv', index_col=0).iloc[304:612]\n",
    "HAB_data.columns = HAB_data.columns.str.replace(' ', '_')\n",
    "\n",
    "# Put columns in alphabetical order\n",
    "sorted_columns = sorted(HAB_data.columns)\n",
    "HAB_data = HAB_data[sorted_columns]\n",
    "\n",
    "# Make indices integers and save mapping to dates\n",
    "#date_to_int_map = {i: date for i, date in enumerate(HAB_data.index)}\n",
    "#HAB_data.index = range(len(HAB_data))\n",
    "HAB_data.index = HAB_data.index.astype(int)\n",
    "\n",
    "target = 'Avg_Chloro_(mg/m3)'\n",
    "\n",
    "#HAB_data = HAB_data.drop(['Nitrite_(uM)','Nitrate_(uM)'],axis=1)\n",
    "\n",
    "HAB_data = HAB_data[['Avg_Chloro_(mg/m3)','Nitrate_(uM)','Nitrite_(uM)','Phosphate_(uM)','Silicate_(uM)']]\n",
    "HAB_data = HAB_data.drop('Nitrite_(uM)',axis=1)\n",
    "\n",
    "block = get_block(HAB_data, num_lags=50, tau=1)\n",
    "block\n",
    "#HAB_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block(data, num_lags=1, tau=1):\n",
    "    ''' Get a dataframe with all the possible valid lags of the variables. '''\n",
    "    \n",
    "    backward_lags = pd.concat([data[var].shift(lag*tau).rename(f'{var}(t-{lag*tau})') for lag in range(num_lags+1) for var in data.columns], axis=1)\n",
    "    forward_lags  = pd.concat([data[var].shift(-1*lag*tau).rename(f'{var}(t+{lag*tau})') for lag in range(1,num_lags+1) for var in data.columns], axis=1)\n",
    "    block = pd.concat([backward_lags, forward_lags], axis=1)\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccm(interaction, block, E_list, tau_list, theta_list, Tp, sample=50, sig=0.05):\n",
    "    print(interaction)\n",
    "    lib = f'1 {len(block)}'\n",
    "    \n",
    "    # Get dataframe with two species of interest\n",
    "    A = interaction[0]; B = interaction[1]\n",
    "    df = block[[f'{A}(t-0)', f'{B}(t-0)']]\n",
    "    \n",
    "    driver = f'{A}(t-0)'\n",
    "    \n",
    "    E_tau_theta_results = pd.DataFrame(columns = ['E', 'tau', 'theta', 'rho'])\n",
    "    for E, tau, theta in list(product(E_list, tau_list, theta_list)):\n",
    "        driven_embedded = [f'{B}(t{i})' if i < 0 else f'{B}(t-{i})' for i in range(E * tau, 1)]\n",
    "        driven_embedded = driven_embedded[::tau][:E]\n",
    "        c = SMap(dataFrame=block, target=driver, columns=driven_embedded, embedded=True, Tp=Tp, theta=theta, lib=lib, pred=lib, noTime=True)\n",
    "        c = c['predictions'][['Observations', 'Predictions']]\n",
    "        rho = c.corr().iloc[0,1]\n",
    "        E_tau_theta_results.loc[len(E_tau_theta_results)] = [E, tau, theta, rho]\n",
    "    E_tau_theta_results = E_tau_theta_results.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Assign E, tau, and theta to be the optimal E, tau, and theta\n",
    "    ccm_value = E_tau_theta_results['rho'].max()\n",
    "    E = int(E_tau_theta_results.loc[np.where(E_tau_theta_results.rho==ccm_value),'E'].item())\n",
    "    tau = int(E_tau_theta_results.loc[np.where(E_tau_theta_results.rho==ccm_value),'tau'].item())\n",
    "    theta = int(E_tau_theta_results.loc[np.where(E_tau_theta_results.rho==ccm_value),'theta'].item())\n",
    "        \n",
    "    # Get convergence p-value\n",
    "    convergence_p_value = get_convergence_p_value(block, sample, A, B, E, Tp, tau, theta)\n",
    "\n",
    "    # Preparing Output\n",
    "    output = {\n",
    "        'target (driver)': A,\n",
    "        'lib (driven)': B,\n",
    "        'E': E,\n",
    "        'tau': tau,\n",
    "        'theta': theta,\n",
    "        'E_tau_theta_results': E_tau_theta_results,\n",
    "        'ccm_value': ccm_value,\n",
    "        'convergence_p_value': convergence_p_value,\n",
    "        'correlation': df.corr().iloc[0,1]\n",
    "    }\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_convergence_p_value(df, sample, A, B, E, Tp, tau, theta):\n",
    "    # Get convergence p-value for CCM (one-tailed t-test on cross-map values using 20% and 50% library sizes)\n",
    "    # H0: μ_20% ≥ μ_50%\n",
    "    # HA: μ_20% < μ_50%\n",
    "    # If p < 0.05, the 20% library size trials have a rho that is significantly smaller than the 50% library trials  \n",
    "    \n",
    "    libsize1 = int(np.ceil(df.shape[0]/5))   # 20% of the full library size\n",
    "    libsize2 = int(np.ceil(df.shape[0]/2))   # 50% of the full library size\n",
    "    \n",
    "    max_iterations = 10 * sample\n",
    "    \n",
    "    # Get list of rhos for libsize1\n",
    "    rhos1 = []; iteration_count = 0\n",
    "    while len(rhos1) < sample and iteration_count < max_iterations:\n",
    "        start = np.random.randint(libsize1, len(df))\n",
    "        library = [start - libsize1, start]\n",
    "        data_subset = df.iloc[library[0]:library[1]]\n",
    "        lib = f'{library[0]+1} {library[1]+1}'\n",
    "        driver = f'{A}(t-0)'\n",
    "        driven_embedded = [f'{B}(t{i})' if i < 0 else f'{B}(t-{i})' for i in range(E * tau, 1)]\n",
    "        driven_embedded = driven_embedded[::tau][:E]\n",
    "        c = SMap(dataFrame=block, target=driver, columns=driven_embedded, embedded=True, Tp=Tp, theta=theta, lib=lib, pred=lib, noTime=True)\n",
    "        c = c['predictions'][['Observations', 'Predictions']]\n",
    "        rho1 = c.corr().iloc[0,1]\n",
    "        if not np.isnan(rho1):\n",
    "            rhos1.append(rho1)\n",
    "        iteration_count += 1\n",
    "        \n",
    "    # Get list of rhos for libsize2\n",
    "    rhos2 = []; iteration_count = 0\n",
    "    while len(rhos2) < sample and iteration_count < max_iterations:\n",
    "        start = np.random.randint(libsize2, len(df))\n",
    "        library = [start - libsize2, start]\n",
    "        data_subset = df.iloc[library[0]:library[1]]\n",
    "        lib = f'{library[0]+1} {library[1]+1}'\n",
    "        driver = f'{A}(t-0)'\n",
    "        driven_embedded = [f'{B}(t{i})' if i < 0 else f'{B}(t-{i})' for i in range(E * tau, 1)]\n",
    "        driven_embedded = driven_embedded[::tau][:E]\n",
    "        c = SMap(dataFrame=block, target=driver, columns=driven_embedded, embedded=True, Tp=Tp, theta=theta, lib=lib, pred=lib, noTime=True)\n",
    "        c = c['predictions'][['Observations', 'Predictions']]\n",
    "        rho2 = c.corr().iloc[0,1]\n",
    "        if not np.isnan(rho2):\n",
    "            rhos2.append(rho2)\n",
    "        iteration_count += 1\n",
    "    \n",
    "    convergence_t_stat, convergence_p_value = ttest_ind(rhos1, rhos2, alternative='less')\n",
    "    \n",
    "    return convergence_p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 interactions\n",
      "('Avg_Chloro_(mg/m3)', 'Phosphate_(uM)')\n",
      "('Avg_Chloro_(mg/m3)', 'Silicate_(uM)')\n",
      "('Nitrate_(uM)', 'Avg_Chloro_(mg/m3)')\n",
      "('Avg_Chloro_(mg/m3)', 'Nitrate_(uM)')\n",
      "('Silicate_(uM)', 'Avg_Chloro_(mg/m3)')\n",
      "('Phosphate_(uM)', 'Avg_Chloro_(mg/m3)')\n"
     ]
    }
   ],
   "source": [
    "E_list = range(2,13)\n",
    "tau_list = [-1,-2,-3]\n",
    "theta_list = [0,0.1,0.5,1,2,3,4,5,6,7,8,9]\n",
    "Tp = 0\n",
    "exclusion_radius = 0\n",
    "\n",
    "all_ccm_results = pd.DataFrame()\n",
    "interactions = list(permutations(HAB_data.columns.tolist(),2))\n",
    "target_interactions = [pair for pair in interactions if target in pair]\n",
    "\n",
    "interaction = target_interactions[0]\n",
    "print(f'There are {len(target_interactions)} interactions')\n",
    "\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(ccm)(interaction, block, E_list, tau_list, theta_list, Tp) for interaction in target_interactions)\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target (driver)</th>\n",
       "      <th>lib (driven)</th>\n",
       "      <th>E</th>\n",
       "      <th>tau</th>\n",
       "      <th>theta</th>\n",
       "      <th>ccm_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silicate_(uM)</td>\n",
       "      <td>Avg_Chloro_(mg/m3)</td>\n",
       "      <td>7</td>\n",
       "      <td>-3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.467497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avg_Chloro_(mg/m3)</td>\n",
       "      <td>Nitrate_(uM)</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.355231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target (driver)        lib (driven)  E  tau  theta  ccm_value\n",
       "0       Silicate_(uM)  Avg_Chloro_(mg/m3)  7   -3      4   0.467497\n",
       "1  Avg_Chloro_(mg/m3)        Nitrate_(uM)  5   -3      9   0.355231"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system variables: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Avg_Chloro_(mg/m3)', 'Nitrate_(uM)', 'Silicate_(uM)']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get CCM results that show convergence (convergence p-value < 0.05)\n",
    "\n",
    "ccm_cutoff = 0.1\n",
    "\n",
    "significant_results = results_df[results_df.convergence_p_value<0.05]\n",
    "significant_results = significant_results.sort_values(by='ccm_value', ascending=False)\n",
    "significant_results = significant_results[['target (driver)', 'lib (driven)', 'E', 'tau', 'theta', 'ccm_value']].reset_index(drop=True)\n",
    "\n",
    "display(significant_results[significant_results.ccm_value>ccm_cutoff])\n",
    "\n",
    "# Choose system variables where the CCM value to or from the target is > ccm_cutoff\n",
    "system_variables = significant_results[significant_results.ccm_value > ccm_cutoff]\n",
    "system_variables = system_variables[['target (driver)', 'lib (driven)']].values.flatten().tolist()\n",
    "system_variables = list(set(system_variables))\n",
    "print('system variables: ')\n",
    "display(sorted(system_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nitrate_(uM)(t-0)',\n",
       " 'Nitrate_(uM)(t-3)',\n",
       " 'Nitrate_(uM)(t+3)',\n",
       " 'Silicate_(uM)(t-0)',\n",
       " 'Silicate_(uM)(t-3)',\n",
       " 'Silicate_(uM)(t+3)']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_valid_lags_tau(block, target, Tp, tau, num_lags, exclusion_radius, system_variables):\n",
    "    \n",
    "    # Get lags of system variables\n",
    "    system_variable_lags = []\n",
    "    for var in system_variables:\n",
    "        # Get forwards and backwards lag of the system variables\n",
    "        var_backwards_lags = [f'{var}(t{i})' if i < 0 else f'{var}(t-{i})' for i in range(num_lags * tau, 1)]\n",
    "        var_backwards_lags = var_backwards_lags[::tau][:num_lags]\n",
    "        var_forwards_lags  = [f'{var}(t+{i})' for i in range(-(num_lags-1) * tau + 1)]\n",
    "        var_forwards_lags  = var_forwards_lags[::tau][:num_lags-1]\n",
    "        var_lags = var_backwards_lags + var_forwards_lags\n",
    "        system_variable_lags = system_variable_lags + var_lags\n",
    "    \n",
    "    # Remove (t-0) lag of target variable from valid_lags\n",
    "    valid_lags = [x for x in system_variable_lags if x != f'{target}(t-0)']\n",
    "\n",
    "    # If Tp = 0, remove [-exclusion_radius, exclusion_radius] lags of target variable from valid lags\n",
    "    if Tp == 0:\n",
    "        for r in range(-exclusion_radius, exclusion_radius+1):\n",
    "            if r < 0:\n",
    "                valid_lags = [x for x in valid_lags if x != f'{target}(t{r})']\n",
    "            elif r == 0:\n",
    "                valid_lags = [x for x in valid_lags if x != f'{target}(t-{r})']\n",
    "            elif r > 0:\n",
    "                valid_lags = [x for x in valid_lags if x != f'{target}(t+{r})']\n",
    "                    \n",
    "    return valid_lags\n",
    "\n",
    "#target = 'Planktothrix_rubescens'\n",
    "system_variables = system_variables\n",
    "Tp = 0\n",
    "exclusion_radius = 6\n",
    "num_lags = 2   # Use -3, 0, and +3 lags of each variable\n",
    "tau = -3\n",
    "\n",
    "valid_lags = get_valid_lags_tau(block, target, Tp, tau, num_lags, exclusion_radius, system_variables)\n",
    "valid_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m max_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000000\u001b[39m\n\u001b[1;32m      7\u001b[0m trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m(embeddings) \u001b[38;5;241m<\u001b[39m sample \u001b[38;5;129;01mand\u001b[39;00m trials \u001b[38;5;241m<\u001b[39m max_trials:\n\u001b[1;32m      9\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(random\u001b[38;5;241m.\u001b[39msample(valid_lags, E))\n\u001b[1;32m     10\u001b[0m     sorted_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28msorted\u001b[39m(embedding))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random_embeddings = {}\n",
    "for E in range(4,26):\n",
    "    # Get random embeddings using valid lags\n",
    "    embeddings = set()\n",
    "    sample = 100000\n",
    "    max_trials = 10000000\n",
    "    trials = 0\n",
    "    while len(embeddings) < sample and trials < max_trials:\n",
    "        embedding = tuple(random.sample(valid_lags, E))\n",
    "        sorted_embedding = tuple(sorted(embedding))\n",
    "        if sorted_embedding not in embeddings:\n",
    "            embeddings.add(sorted_embedding)\n",
    "    trials += 1\n",
    "    embeddings = [list(embedding) for embedding in embeddings]\n",
    "    random_embeddings['{0}'.format((target, E, Tp, exclusion_radius))] = embeddings\n",
    "    print(f'E = {E}, # embeddings = {len(embeddings)}')\n",
    "    \n",
    "with open('random_embeddings_HAB.pkl', 'wb') as file:\n",
    "     pickle.dump(random_embeddings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HAB random embeddings\n",
    "with open('random_embeddings_HAB.pkl', 'rb') as file:\n",
    "    HAB_embeddings = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to store xmap results\n",
    "folder = 'xmap results HAB 100000 random embeddings'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save HAB cross-mapping results\n",
    "\n",
    "E_list = range(4,25)\n",
    "theta_list = [1,5,9,15,25,35,45]\n",
    "Tp = 0\n",
    "exclusion_radius = 6\n",
    "self_weight = 0  # self_weight = 0 for gap filling\n",
    "lib = '1 396' #CHANGE TO LIBRARY SIZE\n",
    "pred = '1 396'\n",
    "\n",
    "total_iterations = len(E_list) * len(theta_list)\n",
    "\n",
    "gapfill_results = {}\n",
    "parameters = pd.DataFrame(columns=['target', 'noise_level', 'lib', 'pred', 'E', 'theta', 'k', 'rho'])\n",
    "block = get_block(HAB_data, num_lags=50)\n",
    "\n",
    "with tqdm(total=total_iterations) as pbar:\n",
    "    for E, theta in product(E_list, theta_list):\n",
    "\n",
    "        key = [key for key in HAB_embeddings.keys() if eval(key)[0] == target and eval(key)[1] == E and eval(key)[2] == Tp and eval(key)[3] == exclusion_radius]\n",
    "        embeddings = HAB_embeddings[key[0]]\n",
    "\n",
    "        xmap_results = get_xmap_results_smap(block, f'{target}(t-0)', embeddings, Tp, theta, lib, lib)\n",
    "\n",
    "        file_path = os.path.join(folder, f'xmap_results_{target}_Tp_{Tp}_E_{E}_theta_{theta}.pkl')\n",
    "\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(xmap_results, f)\n",
    "\n",
    "        pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyedm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
